#!/bin/sh

# postinst script for spark2
#
# see: dh_installdeb(1)

set -e


case "$1" in
    configure|reconfigure)
        if ! getent passwd spark >/dev/null; then
            # Adding system user: spark.
            adduser \
                --system \
                --group \
                --no-create-home \
                --home /nonexistent \
                --gecos "Spark" \
                --shell /bin/false \
                spark >/dev/null 2>/dev/null || :
        fi


        # If /etc/hadoop/conf exists, assume an HDFS client exists and is useable.
        # Automate storing spark2-assembly.jar into HDFS.
        if [ -e /etc/hadoop/conf -a -x $(which hdfs) ]; then
            sudo -u spark hdfs dfs -mkdir -p /user/spark/share/lib && \
            sudo -u spark hdfs dfs -put -f /usr/lib/spark2/spark2-assembly.zip /user/spark/share/lib/spark2-assembly.zip && \
            # Append configuration to spark-defaults.conf to use spark2-assembly.zip
            echo 'spark.yarn.archive                  hdfs:///user/spark/share/lib/spark2-assembly.zip' >> /etc/spark2/conf/spark-defaults.conf
        fi

        # Symlink hive-site.xml into spark2/conf if it exists.
        # This lets spark2 infer Hive configuration.
        test -f /etc/hive/conf/hive-site.xml && ln -sf /etc/hive/conf/hive-site.xml /etc/spark2/conf/hive-site.xml
        ;;

    abort-upgrade|abort-remove|abort-deconfigure)
        ;;

    *)
        echo "postinst called with unknown argument \`$1'" >&2
        exit 1
        ;;
esac





# dh_installdeb will replace this with shell code automatically
# generated by other debhelper scripts.

#DEBHELPER#

exit 0
